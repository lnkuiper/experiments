{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d15b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import lorem\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152e6711",
   "metadata": {},
   "source": [
    "# Source Column Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a7f956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DATA_DIR = 'source'\n",
    "if not os.path.exists(SOURCE_DATA_DIR):\n",
    "    os.mkdir(SOURCE_DATA_DIR)\n",
    "    \n",
    "GROUPS_DATA_DIR = 'groups'\n",
    "if not os.path.exists(GROUPS_DATA_DIR):\n",
    "    os.mkdir(GROUPS_DATA_DIR)\n",
    "\n",
    "NL = '\\n'\n",
    "TAB = '\\t'\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ec6143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2d8245",
   "metadata": {},
   "source": [
    "## Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b963162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distinct_string_data(con, name, min_strlen, max_strlen, count):\n",
    "    file = f\"{SOURCE_DATA_DIR}/{name}_strings.parquet\"\n",
    "    if os.path.exists(file):\n",
    "        return\n",
    "    \n",
    "    l = [c for c in list(lorem.text()) if c != '\\r' ]\n",
    "    source_string = ''\n",
    "    \n",
    "    offset_in_source = 0\n",
    "    strlen_range = max_strlen - min_strlen\n",
    "    \n",
    "    unique_strings = set()\n",
    "    while (len(unique_strings) < count):\n",
    "        strlen = min_strlen + math.ceil(random.random() * strlen_range)\n",
    "        \n",
    "        if offset_in_source + strlen > len(source_string):\n",
    "            random.shuffle(l)\n",
    "            source_string = ''.join(l)\n",
    "            offset_in_source = 0\n",
    "        \n",
    "        unique_strings.add(source_string[offset_in_source:offset_in_source + strlen])\n",
    "        offset_in_source += strlen\n",
    "    \n",
    "    unique_strings = pd.DataFrame(list(unique_strings), columns=['c0'])\n",
    "    con.execute(f\"\"\"\n",
    "    COPY (SELECT * FROM unique_strings)\n",
    "    TO '{file}'\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36c6891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_params = [\n",
    "    ('tiny', 1, 1, 20),\n",
    "    ('small', 4, 7, int(1e6)),\n",
    "    ('medium', 8, 15, int(1e6)),\n",
    "    ('large', 16, 31, int(1e6)),\n",
    "    ('huge', 32, 63, int(1e6)),\n",
    "]\n",
    "\n",
    "for param in string_params:\n",
    "    create_distinct_string_data(con, *param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e761d3dc",
   "metadata": {},
   "source": [
    "## Integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1510ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = {\n",
    "    'tinyint': (1 << 7) - 1,\n",
    "    'smallint': (1 << 15) - 1,\n",
    "    'integer': (1 << 31) - 1,\n",
    "    'bigint': (1 << 63) - 1,\n",
    "}\n",
    "\n",
    "def create_distinct_integral_data(con, t, count):\n",
    "    file = f\"{SOURCE_DATA_DIR}/{t}s.parquet\"\n",
    "    if os.path.exists(file):\n",
    "        return\n",
    "    \n",
    "    limit = limits[t]\n",
    "    con.execute(f\"\"\"\n",
    "    COPY (SELECT DISTINCT CAST(random() * {limit} - {limit} / 2 AS {t}) c0\n",
    "          FROM range({count})\n",
    "    ) TO '{file}'\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c53b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_params = [\n",
    "    ('tinyint', 100),\n",
    "    ('smallint', 10000),\n",
    "    ('integer', int(1e8)),\n",
    "    ('bigint', int(1e8)),\n",
    "]\n",
    "\n",
    "for param in integral_params:\n",
    "    create_distinct_integral_data(con, *param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71f1a6",
   "metadata": {},
   "source": [
    "# Group Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d07f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_groups(group_cols, group_count):\n",
    "    group_unique_counts = []\n",
    "    num_group_cols = len(group_cols)\n",
    "    remaining_group_count = group_count\n",
    "    for i in range(num_group_cols):\n",
    "        assert(len(group_cols[i]) == 2)\n",
    "        group_type = group_cols[i][0]\n",
    "        group_weight = group_cols[i][1]\n",
    "        assert(group_weight >= 0 and group_weight <= 1)\n",
    "        remaining_group_cols = num_group_cols - i\n",
    "        group_pow = (1 / remaining_group_cols) ** (1 - group_weight)\n",
    "        assert(group_pow >= 0 and group_pow <= 1)\n",
    "        group_unique_count = math.ceil(remaining_group_count ** group_pow)\n",
    "        remaining_group_count /= group_unique_count\n",
    "        group_unique_counts.append(group_unique_count)\n",
    "    return f\"\"\"\\rSELECT{TAB}row_number() OVER () AS group_id, *\n",
    "               \\rFROM{f',{NL}'.join([f\"{TAB}(SELECT c0 AS c{i} FROM '{SOURCE_DATA_DIR}/{t}s.parquet' USING SAMPLE {c}) t{i}\" for i, (t, c) in enumerate(zip([gc[0] for gc in group_cols], group_unique_counts))])}\n",
    "               \\rLIMIT{TAB}{group_count}\n",
    "           \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "560d6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(file, group_cols, group_count, total_count, power, test_run=True):\n",
    "    group_ids = np.arange(group_count)\n",
    "    distribution = (np.random.power(power, total_count) * group_count).astype(int)\n",
    "    occurrences_df = pd.DataFrame(np.take(group_ids, distribution), columns=['group_id'])\n",
    "    \n",
    "    if test_run:\n",
    "        print(con.execute(\"\"\"\n",
    "        WITH counts_per_group AS (\n",
    "            SELECT group_id, count(*) count\n",
    "            FROM occurrences_df\n",
    "            GROUP BY group_id\n",
    "        )\n",
    "        SELECT min(count) AS mi,\n",
    "               max(count) AS ma,\n",
    "               median(count) AS med,\n",
    "               avg(count) AS avg,\n",
    "               sum(count) AS s,\n",
    "               count(*) AS groups\n",
    "        from counts_per_group\n",
    "        \"\"\").fetchdf())\n",
    "        \n",
    "        print(\"Is the generated distribution OK? [y/n]\")\n",
    "        a = input()\n",
    "        if a == 'n':\n",
    "            return\n",
    "        elif a != 'y':\n",
    "            print(\"Input must be y/n!\")\n",
    "    \n",
    "    # Create groups\n",
    "    q = generate_unique_groups(group_cols, group_count)\n",
    "    con.execute(f\"CREATE OR REPLACE VIEW groups AS ({q})\")\n",
    "    \n",
    "    # Join them\n",
    "    con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT groups.* EXCLUDE (group_id)\n",
    "        FROM groups\n",
    "        JOIN occurrences_df\n",
    "        USING (group_id)\n",
    "    ) TO '{file}'\n",
    "    \"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca56420f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {align:left;display:block}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {align:left;display:block}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8df225",
   "metadata": {},
   "source": [
    "We can choose from:\n",
    "| table | width | unique |\n",
    "|:---|:---:|:---:|\n",
    "|`'tinyints'` | 1 | 100 |\n",
    "|`'smallints'` | 2 | 10.000 |\n",
    "|`'integers'` | 4 | 100.000.000 |\n",
    "|`'bigints'` | 8 | 100.000.000 |\n",
    "|`'tiny_strings'` | 1 | 20 |\n",
    "|`'small_strings'` | 4-7 | 1.000.000 |\n",
    "|`'medium_strings'` | 8-15 | 1.000.000 |\n",
    "|`'large_strings'` | 16-31 | 1.000.000 |\n",
    "|`'huge_strings'` | 32-63 | 1.000.000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e128a129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d909be7e914d7b9725169994858baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9058e78978e144c1ac4ee04b7c09878a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_count = int(1e8)\n",
    "for type_ in ['integer', 'bigint']:\n",
    "    type_dir_name = GROUPS_DATA_DIR + '/' + type_\n",
    "    if not os.path.exists(type_dir_name):\n",
    "        os.mkdir(type_dir_name)\n",
    "        \n",
    "    for column_count in [1, 2, 4, 8, 16]:\n",
    "        column_dir_name = type_dir_name + f'/columns={column_count}'\n",
    "        if not os.path.exists(column_dir_name):\n",
    "            os.mkdir(column_dir_name)\n",
    "            \n",
    "        group_cols = [(type_, 0) for _ in range(column_count)]\n",
    "        \n",
    "        for power in [1, 5, 10, 15, 20]:\n",
    "            power_dir_name = column_dir_name + f'/power={power}'\n",
    "            if not os.path.exists(power_dir_name):\n",
    "                os.mkdir(power_dir_name)\n",
    "            \n",
    "            # From 1k to 100M groups\n",
    "            for gce in range(3, 9):\n",
    "                group_count = 10 ** gce\n",
    "                file_name = power_dir_name + f'/{group_count}.csv'\n",
    "                if os.path.exists(file_name):\n",
    "                    continue\n",
    "                \n",
    "                generate_dataset(file_name, group_cols, group_count, total_count, power, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f908da",
   "metadata": {},
   "source": [
    "# Random Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before = time.time()\n",
    "# con.execute(f\"\"\"\n",
    "# WITH hits_per_user AS (\n",
    "#     SELECT c0, count(*) AS count\n",
    "#     FROM '{GROUPS_DATA_DIR}/clickbench*.parquet'\n",
    "#     GROUP BY c0\n",
    "# )\n",
    "# select min(count) mi, max(count) ma, median(count) med, avg(count) avg, sum(count) s\n",
    "# FROM hits_per_user\n",
    "# \"\"\")\n",
    "# print(time.time() - before)\n",
    "# con.fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f079c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
